{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetNeighbors: Domain Discovery Using CommonCrawl Webgraph\n",
    "\n",
    "Discover related domains using link topology analysis from the CommonCrawl web graph.\n",
    "\n",
    "This notebook uses py4j to maintain a persistent JVM with the graph loaded in memory.\n",
    "After initial load (~5 seconds), queries are **nearly instant**.\n",
    "\n",
    "**Run the cells below in order to set up and use the discovery tool.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check RAM and setup working directory\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Available RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: You need Colab Pro for this notebook!\")\n",
    "    print(\"   Required: 20GB+ RAM\")\n",
    "    print(f\"   You have: {ram_gb:.1f} GB\")\n",
    "    print(\"\\n   Please enable High-RAM runtime:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Runtime shape: High-RAM\")\n",
    "    raise Exception(\"Insufficient RAM. Please upgrade runtime.\")\n",
    "else:\n",
    "    print(\"‚úÖ Sufficient RAM available\\n\")\n",
    "\n",
    "# Determine NetNeighbors location and set as working directory\n",
    "if os.path.exists(\"/content\"):\n",
    "    # Colab environment\n",
    "    if not os.path.exists(\"/content/NetNeighbors\"):\n",
    "        print(\"Cloning NetNeighbors repository...\")\n",
    "        !git clone --depth 1 https://github.com/PeterCarragher/NetNeighbors.git /content/NetNeighbors > /dev/null 2>&1\n",
    "        print(\"‚úÖ Repository cloned\")\n",
    "    else:\n",
    "        print(\"‚úÖ NetNeighbors repository already exists\")\n",
    "    os.chdir(\"/content/NetNeighbors\")\n",
    "else:\n",
    "    # Local environment\n",
    "    if os.path.exists(\"src/DiscoveryTool.java\"):\n",
    "        print(\"‚úÖ Already in NetNeighbors directory\")\n",
    "    elif os.path.exists(\"NetNeighbors/src/DiscoveryTool.java\"):\n",
    "        os.chdir(\"NetNeighbors\")\n",
    "        print(\"‚úÖ Changed to NetNeighbors submodule\")\n",
    "    else:\n",
    "        raise Exception(\"Cannot find NetNeighbors directory.\")\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Environment Setup\n",
    "\n",
    "Installs Java 17, Maven, py4j, and builds the cc-webgraph tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash scripts/setup.sh\n",
    "\n",
    "# Install py4j and gradio\n",
    "!pip install -q py4j gradio\n",
    "print(\"\\n‚úÖ py4j and gradio installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Configure Storage and Download Webgraph\n",
    "\n",
    "Downloads pre-built graph files from CommonCrawl (~23GB total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_storage, download_webgraph\n",
    "\n",
    "# Webgraph version - see https://commoncrawl.org/web-graphs for available versions\n",
    "VERSION = \"cc-main-2024-feb-apr-may\"\n",
    "\n",
    "# Enter GCS bucket name (or leave empty for local storage)\n",
    "GCS_BUCKET = None  # e.g., \"my-webgraph-bucket\"\n",
    "LOCAL_PATH = None  # e.g., \"/mnt/d/dev/data/cc/\"\n",
    "\n",
    "if GCS_BUCKET:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "WEBGRAPH_DIR = setup_storage(bucket_name=GCS_BUCKET, webgraph_dir=LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download webgraph files (skip if already downloaded)\n",
    "download_webgraph(WEBGRAPH_DIR, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Graph Bridge (JVM Backend)\n",
    "\n",
    "This starts a persistent JVM and loads the graph into memory.\n",
    "**Takes ~5 seconds**, but then all queries are nearly instant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_bridge import GraphBridge\n",
    "\n",
    "# Initialize and load graph\n",
    "bridge = GraphBridge(WEBGRAPH_DIR, VERSION)\n",
    "bridge.load_graph()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Graph loaded! Queries are now instant.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Quick Test\n",
    "\n",
    "Let's verify the bridge is working with a quick query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test domain lookup (should be instant)\n",
    "test_domains = [\"cnn.com\", \"bbc.com\", \"foxnews.com\", \"nonexistent.tld\"]\n",
    "\n",
    "start = time.time()\n",
    "found, not_found = bridge.validate_seeds(test_domains)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Validated {len(test_domains)} domains in {elapsed*1000:.1f}ms\")\n",
    "print(f\"Found: {found}\")\n",
    "if not_found:\n",
    "    print(f\"Not found: {not_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discovery Interface\n",
    "\n",
    "Use the Gradio interface below to discover related domains. Queries are **nearly instant** now that the graph is loaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "def run_discovery(domains_text: str, min_connections: int, direction: str):\n",
    "    \"\"\"\n",
    "    Run domain discovery and return results.\n",
    "    \"\"\"\n",
    "    # Parse and validate input\n",
    "    if not domains_text.strip():\n",
    "        return None, \"Please enter at least one domain\", None\n",
    "    \n",
    "    seed_domains = [d.strip() for d in domains_text.strip().split('\\n') if d.strip()]\n",
    "    \n",
    "    if len(seed_domains) == 0:\n",
    "        return None, \"Please enter at least one domain\", None\n",
    "    \n",
    "    if len(seed_domains) > 10000:\n",
    "        return None, \"Maximum 10,000 domains allowed\", None\n",
    "    \n",
    "    # Validate seeds\n",
    "    found, not_found = bridge.validate_seeds(seed_domains)\n",
    "    \n",
    "    status_lines = []\n",
    "    if not_found:\n",
    "        status_lines.append(f\"‚ö†Ô∏è {len(not_found)} domains not found in graph\")\n",
    "        if len(not_found) <= 5:\n",
    "            status_lines.append(f\"   Not found: {', '.join(not_found)}\")\n",
    "        else:\n",
    "            status_lines.append(f\"   Not found: {', '.join(not_found[:5])}... and {len(not_found)-5} more\")\n",
    "    \n",
    "    if len(found) == 0:\n",
    "        return None, \"No valid domains found in graph\", None\n",
    "    \n",
    "    status_lines.append(f\"‚úÖ {len(found)} valid seed domains\")\n",
    "    \n",
    "    # Run discovery\n",
    "    direction_value = \"backlinks\" if \"Backlinks\" in direction else \"outlinks\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        results = bridge.discover(\n",
    "            seed_domains=found,\n",
    "            min_connections=min_connections,\n",
    "            direction=direction_value\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return None, f\"Error: {str(e)}\", None\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        status_lines.append(f\"\\n‚è±Ô∏è Completed in {elapsed:.2f}s\")\n",
    "        status_lines.append(\"\\nNo domains found. Try lowering min connections.\")\n",
    "        return None, \"\\n\".join(status_lines), None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = \"/content/results.csv\" if os.path.exists(\"/content\") else \"results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Build status message\n",
    "    status_lines.append(f\"\\n‚è±Ô∏è Completed in {elapsed:.2f}s\")\n",
    "    status_lines.append(f\"\\nüìä Results: {len(df):,} domains\")\n",
    "    status_lines.append(f\"   Connections range: {df['connections'].min():.0f} - {df['connections'].max():.0f}\")\n",
    "    status_lines.append(f\"   Mean: {df['connections'].mean():.1f} | Median: {df['connections'].median():.0f}\")\n",
    "    status_lines.append(f\"\\nüíæ Saved to {csv_path}\")\n",
    "    \n",
    "    return df.head(500), \"\\n\".join(status_lines), csv_path\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"NetNeighbors - Domain Discovery\") as demo:\n",
    "    gr.Markdown(\"## üîç Domain Discovery\")\n",
    "    gr.Markdown(\"Find related domains using CommonCrawl webgraph link analysis.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            seeds_input = gr.Textbox(\n",
    "                label=\"Seed Domains\",\n",
    "                placeholder=\"Enter domains, one per line:\\ncnn.com\\nbbc.com\\nfoxnews.com\",\n",
    "                lines=10,\n",
    "                max_lines=20\n",
    "            )\n",
    "            \n",
    "            min_conn = gr.Slider(\n",
    "                minimum=1,\n",
    "                maximum=100,\n",
    "                value=3,\n",
    "                step=1,\n",
    "                label=\"Minimum Connections\",\n",
    "                info=\"Only show domains connected to at least this many seeds\"\n",
    "            )\n",
    "            \n",
    "            direction = gr.Radio(\n",
    "                choices=[\"Backlinks (who links TO seeds)\", \"Outlinks (who seeds link TO)\"],\n",
    "                value=\"Backlinks (who links TO seeds)\",\n",
    "                label=\"Direction\"\n",
    "            )\n",
    "            \n",
    "            run_btn = gr.Button(\"üöÄ Run Discovery\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            status_output = gr.Textbox(\n",
    "                label=\"Status\",\n",
    "                lines=8,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            results_table = gr.Dataframe(\n",
    "                label=\"Results (top 500)\",\n",
    "                headers=[\"domain\", \"connections\", \"percentage\"],\n",
    "                wrap=True\n",
    "            )\n",
    "            \n",
    "            download_file = gr.File(label=\"Download Full Results\")\n",
    "    \n",
    "    run_btn.click(\n",
    "        fn=run_discovery,\n",
    "        inputs=[seeds_input, min_conn, direction],\n",
    "        outputs=[results_table, status_output, download_file]\n",
    "    )\n",
    "\n",
    "# Launch embedded in notebook\n",
    "demo.launch(inline=True, share=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Direct API Usage (Optional)\n",
    "\n",
    "You can also use the GraphBridge API directly for programmatic access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Direct API usage\n",
    "seeds = [\"cnn.com\", \"bbc.com\", \"foxnews.com\"]\n",
    "\n",
    "# Discover with counts\n",
    "results = bridge.discover_backlinks(seeds, min_connections=3)\n",
    "print(f\"Found {len(results)} domains\")\n",
    "for r in results[:10]:\n",
    "    print(f\"  {r['domain']}: {r['connections']} connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fast discovery (no counts, Java-side filtering)\n",
    "domains = bridge.discover_fast(seeds, min_connections=3, direction=\"backlinks\")\n",
    "print(f\"Found {len(domains)} domains (fast mode)\")\n",
    "print(domains[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "When done, shutdown the JVM to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to shutdown JVM\n",
    "# bridge.shutdown()\n",
    "# print(\"JVM shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
