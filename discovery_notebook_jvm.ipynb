{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetNeighbors: Domain Discovery Using CommonCrawl Webgraph\n",
    "\n",
    "**High-Performance JVM Backend**\n",
    "\n",
    "Discover related domains using link topology analysis from the CommonCrawl web graph.\n",
    "\n",
    "This notebook uses py4j to maintain a persistent JVM with the graph loaded in memory.\n",
    "After initial load (~5 seconds), queries are **nearly instant**.\n",
    "\n",
    "**Run the cells below in order to set up and use the discovery tool.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 31.0 GB\n",
      "‚úÖ Sufficient RAM available\n",
      "\n",
      "‚úÖ Changed to NetNeighbors submodule\n",
      "Working directory: /home/peter/dev/apps/NetNeighborsColab/NetNeighbors\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check RAM and setup working directory\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Available RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: You need Colab Pro for this notebook!\")\n",
    "    print(\"   Required: 20GB+ RAM\")\n",
    "    print(f\"   You have: {ram_gb:.1f} GB\")\n",
    "    print(\"\\n   Please enable High-RAM runtime:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Runtime shape: High-RAM\")\n",
    "    raise Exception(\"Insufficient RAM. Please upgrade runtime.\")\n",
    "else:\n",
    "    print(\"‚úÖ Sufficient RAM available\\n\")\n",
    "\n",
    "# Determine NetNeighbors location and set as working directory\n",
    "if os.path.exists(\"/content\"):\n",
    "    # Colab environment\n",
    "    if not os.path.exists(\"/content/NetNeighbors\"):\n",
    "        print(\"Cloning NetNeighbors repository...\")\n",
    "        !git clone --depth 1 https://github.com/PeterCarragher/NetNeighbors.git /content/NetNeighbors > /dev/null 2>&1\n",
    "        print(\"‚úÖ Repository cloned\")\n",
    "    else:\n",
    "        print(\"‚úÖ NetNeighbors repository already exists\")\n",
    "    os.chdir(\"/content/NetNeighbors\")\n",
    "else:\n",
    "    # Local environment\n",
    "    if os.path.exists(\"src/DiscoveryTool.java\"):\n",
    "        print(\"‚úÖ Already in NetNeighbors directory\")\n",
    "    elif os.path.exists(\"NetNeighbors/src/DiscoveryTool.java\"):\n",
    "        os.chdir(\"NetNeighbors\")\n",
    "        print(\"‚úÖ Changed to NetNeighbors submodule\")\n",
    "    else:\n",
    "        raise Exception(\"Cannot find NetNeighbors directory.\")\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Environment Setup\n",
    "\n",
    "Installs Java 17, Maven, py4j, and builds the cc-webgraph tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           NetNeighbors Environment Setup\n",
      "============================================================\n",
      "Base directory: /home/peter/dev/apps/NetNeighborsColab\n",
      "NetNeighbors: /home/peter/dev/apps/NetNeighborsColab/NetNeighbors\n",
      "Mode: local\n",
      "\n",
      "1. Setting up Java 17 and Maven...\n",
      "   ‚úÖ Java and Maven already installed\n",
      "openjdk version \"17.0.15\" 2025-04-15\n",
      "\n",
      "2. Skipping gcsfuse (local mode, not needed)\n",
      "\n",
      "3. Installing Python dependencies...\n",
      "   ‚úÖ Python dependencies installed\n",
      "\n",
      "4. Setting up cc-webgraph...\n",
      "   ‚úÖ cc-webgraph already built\n",
      "\n",
      "5. Setting up NetNeighbors...\n",
      "   ‚úÖ DiscoveryTool already compiled\n",
      "\n",
      "============================================================\n",
      "                    Setup Complete!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Download webgraph data (use utils.download_webgraph)\n",
      "  2. Run verify.sh to confirm installation\n",
      "\n",
      "‚úÖ py4j installed\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/setup.sh\n",
    "\n",
    "# Install py4j for JVM bridge\n",
    "!pip install -q py4j\n",
    "print(\"\\n‚úÖ py4j installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Configure Storage and Download Webgraph\n",
    "\n",
    "Downloads pre-built graph files from CommonCrawl (~23GB total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local storage: /mnt/d/dev/data/cc/\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_storage, download_webgraph\n",
    "\n",
    "# Webgraph version - see https://commoncrawl.org/web-graphs for available versions\n",
    "VERSION = \"cc-main-2024-feb-apr-may\"\n",
    "\n",
    "# Enter GCS bucket name (or leave empty for local storage)\n",
    "GCS_BUCKET = None #\"commoncrawl_webgraph\" # e.g., \"my-webgraph-bucket\"\n",
    "LOCAL_PATH = \"/mnt/d/dev/data/cc/\"\n",
    "\n",
    "if GCS_BUCKET:\n",
    "  from google.colab import auth; auth.authenticate_user()\n",
    "WEBGRAPH_DIR = setup_storage(bucket_name=GCS_BUCKET, webgraph_dir=LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CommonCrawl webgraph: cc-main-2024-feb-apr-may\n",
      "Destination: /mnt/d/dev/data/cc/\n",
      "============================================================\n",
      "\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-vertices.txt.gz (889.2 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.graph (4298.4 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.properties (0.0 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-t.graph (4275.1 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-t.properties (0.0 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.stats (0.0 MB)\n",
      "\n",
      "============================================================\n",
      "All graph files downloaded!\n",
      "\n",
      "Building offset files (required for graph queries)...\n",
      "Offsets already exist: cc-main-2024-feb-apr-may-domain.offsets\n",
      "Offsets already exist: cc-main-2024-feb-apr-may-domain-t.offsets\n",
      "\n",
      "============================================================\n",
      "Webgraph ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Download webgraph files (skip if already downloaded)\n",
    "download_webgraph(WEBGRAPH_DIR, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Graph Bridge (JVM Backend)\n",
    "\n",
    "This starts a persistent JVM and loads the graph into memory.\n",
    "**Takes ~5 seconds**, but then all queries are nearly instant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting JVM with cc-webgraph...\n",
      "JAR: /home/peter/dev/apps/NetNeighborsColab/cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\n",
      "Loading graph: /mnt/d/dev/data/cc/cc-main-2024-feb-apr-may-domain\n",
      "This takes ~5 seconds...\n",
      "‚úÖ Graph loaded!\n",
      "Subsequent queries will be nearly instant!\n",
      "\n",
      "============================================================\n",
      "üöÄ Graph loaded! Queries are now instant.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from graph_bridge import GraphBridge\n",
    "\n",
    "# Initialize and load graph (this is the ~10 second step)\n",
    "bridge = GraphBridge(WEBGRAPH_DIR, VERSION)\n",
    "bridge.load_graph()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Graph loaded! Queries are now instant.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Quick Test\n",
    "\n",
    "Let's verify the bridge is working with a quick query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated 7 domains in 10.2ms\n",
      "Found: ['com.cnn', 'com.bbc', 'com.foxnews', 'com.100percentfedup', 'org.4chan', 'org.911truth']\n",
      "Not found: ['tld.nonexistentdomain']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Test domain lookup (should be instant)\n",
    "test_domains = [\"cnn.com\", \"bbc.com\", \"foxnews.com\", \"100percentfedup.com\", \"nonexistentdomain.tld\", \"4chan.org\", \"911truth.org\"]\n",
    "\n",
    "def reverse_domain(domain: str) -> str:\n",
    "    return '.'.join(reversed(domain.split('.')))\n",
    "\n",
    "reversed_domains = [reverse_domain(d) for d in test_domains]\n",
    "\n",
    "start = time.time()\n",
    "found, not_found = bridge.validate_seeds(reversed_domains)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Validated {len(test_domains)} domains in {elapsed*1000:.1f}ms\")\n",
    "print(f\"Found: {found}\")\n",
    "if not_found:\n",
    "    print(f\"Not found: {not_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6 seed domains...\n",
      "Processed 6/6 seeds...\n",
      "Found 569,203 unique neighbor domains\n",
      "Found 46 domains with >= 6 connections\n",
      "\n",
      "Discovery completed in 0.58 seconds\n",
      "Found 46 domains with >= 6 connections\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'domain': 'com.50webs', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.aifsy', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.amgreatness', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.angelfire', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.bitchute', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.blogspot', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.dailycaller', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.ericpetersautos', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.fc2', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.forumotion', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.globalseoarticles', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.henrymakow', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.hubpages', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.kingranks', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.pirdu', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.pklea', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.ranksdirectory', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.salon', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.scienceblogs', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.shtfplan', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.substack', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.topbilliondirectory', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.typepad', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.usawatchdog', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.wayranks', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.webranksite', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.webseodirectory', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.weebly', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.wnd', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'com.worldranksite', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'net.eturkey', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'net.gatesofvienna', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'net.phibetaiota', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'net.saidit', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'online.99site', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'online.allarticles', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'online.waynews', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'online.wayranks', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'org.freedomclubusa', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'org.horsesass', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'org.rationalwiki', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'org.republicbroadcasting', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'org.softpanorama', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'se.vaken', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'tv.thepeoplesvoice', 'connections': 6, 'percentage': 100.0},\n",
       " {'domain': 'us.thepiratescove', 'connections': 6, 'percentage': 100.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Direct API usage\n",
    "import time\n",
    "\n",
    "# Run discovery\n",
    "threshold = 6\n",
    "start = time.time()\n",
    "results = bridge.discover_backlinks(found, min_connections=threshold)\n",
    "# results = bridge.shared_predecessors(found)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nDiscovery completed in {elapsed:.2f} seconds\")\n",
    "print(f\"Found {len(results)} domains with >= {threshold} connections\")\n",
    "# print(\"\\nTop 10 results:\")\n",
    "# for r in results[:10]:\n",
    "#     print(f\"  {r['domain']}: {r['connections']} connections ({r['percentage']}%)\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discovery Interface\n",
    "\n",
    "Use the form below to discover related domains. Queries are **nearly instant** now that the graph is loaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://74edbe394fe92582cb.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://74edbe394fe92582cb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q gradio pandas\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "def run_discovery(domains_text, min_connections, direction):\n",
    "    # --- Validate input ---\n",
    "    if not domains_text or not domains_text.strip():\n",
    "        return \"‚ùå Error: Please enter at least one domain\", None\n",
    "\n",
    "    seed_domains = [d.strip() for d in domains_text.splitlines() if d.strip()]\n",
    "    seed_domains = [reverse_domain(d) for d in seed_domains]\n",
    "    if len(seed_domains) == 0:\n",
    "        return \"‚ùå Error: Please enter at least one domain\", None\n",
    "\n",
    "    if len(seed_domains) > 10000:\n",
    "        return \"‚ùå Error: Maximum 10,000 domains allowed\", None\n",
    "\n",
    "    log_lines = []\n",
    "    log_lines.append(\"Configuration:\")\n",
    "    log_lines.append(f\"  Seed domains: {len(seed_domains)}\")\n",
    "    log_lines.append(f\"  Direction: {direction}\")\n",
    "    log_lines.append(f\"  Min connections: {min_connections}\")\n",
    "    log_lines.append(\"\")\n",
    "\n",
    "    try:\n",
    "        # --- Run discovery ---\n",
    "        start_time = time.time()\n",
    "        results = bridge.discover(\n",
    "            seed_domains=seed_domains,\n",
    "            min_connections=min_connections,\n",
    "            direction=direction\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        log_lines.append(f\"‚è±Ô∏è Query completed in {elapsed:.2f} seconds\")\n",
    "        log_lines.append(\"\")\n",
    "\n",
    "        if len(results) == 0:\n",
    "            log_lines.extend([\n",
    "                \"No Results Found\",\n",
    "                \"\",\n",
    "                \"Try:\",\n",
    "                \"  - Lowering the minimum connections threshold\",\n",
    "                \"  - Using different seed domains\",\n",
    "                \"  - Switching between backlinks and outlinks\"\n",
    "            ])\n",
    "            return \"\\n\".join(log_lines), None\n",
    "\n",
    "        # --- Convert to DataFrame ---\n",
    "        df = pd.DataFrame(results)\n",
    "        # reverse urls back to normal format\n",
    "        df['domain'] = df['domain'].apply(lambda d: '.'.join(reversed(d.split('.'))))\n",
    "\n",
    "        # --- Summary stats ---\n",
    "        log_lines.append(\"=\" * 60)\n",
    "        log_lines.append(\"Summary Statistics:\")\n",
    "        log_lines.append(f\"  Total discovered: {len(df):,} domains\")\n",
    "        log_lines.append(\n",
    "            f\"  Connections range: {df['connections'].min():.0f} - {df['connections'].max():.0f}\"\n",
    "        )\n",
    "        log_lines.append(f\"  Mean connections: {df['connections'].mean():.1f}\")\n",
    "        log_lines.append(f\"  Median connections: {df['connections'].median():.0f}\")\n",
    "        log_lines.append(\"=\" * 60)\n",
    "\n",
    "        # --- Save CSV ---\n",
    "        csv_path = \"/content/results.csv\" if os.path.exists(\"/content\") else \"results.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        log_lines.append(f\"\\nüíæ Results saved to {csv_path}\")\n",
    "\n",
    "        return \"\\n\".join(log_lines), df\n",
    "\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return f\"‚ùå Error during discovery:\\n{str(e)}\\n\\n{tb}\", None\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"News Source Discovery\") as demo:\n",
    "    gr.Markdown(\"## Seed Domains\")\n",
    "    gr.Markdown(\"Enter one domain per line:\")\n",
    "\n",
    "    domains_input = gr.Textbox(\n",
    "        placeholder=\"cnn.com\\nbbc.com\\nfoxnews.com\",\n",
    "        lines=8,\n",
    "        label=None\n",
    "    )\n",
    "\n",
    "    min_conn_slider = gr.Slider(\n",
    "        minimum=1,\n",
    "        maximum=100,\n",
    "        value=5,\n",
    "        step=1,\n",
    "        label=\"Min Connections\"\n",
    "    )\n",
    "\n",
    "    direction_radio = gr.Radio(\n",
    "        choices=[\n",
    "            (\"Backlinks (who links TO seeds)\", \"backlinks\"),\n",
    "            (\"Outlinks (who seeds link TO)\", \"outlinks\"),\n",
    "        ],\n",
    "        value=\"backlinks\",\n",
    "        label=\"Direction\"\n",
    "    )\n",
    "\n",
    "    run_button = gr.Button(\"üöÄ Run Discovery\")\n",
    "\n",
    "    gr.Markdown(\"---\")\n",
    "\n",
    "    output_log = gr.Textbox(\n",
    "        label=\"Run Log\",\n",
    "        lines=14,\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "    output_table = gr.Dataframe(\n",
    "        label=\"Top Results (sortable)\",\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "    run_button.click(\n",
    "        fn=run_discovery,\n",
    "        inputs=[domains_input, min_conn_slider, direction_radio],\n",
    "        outputs=[output_log, output_table]\n",
    "    )\n",
    "\n",
    "demo.launch(inline=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "When done, you can shutdown the JVM to free memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39925)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peter/miniconda3/envs/net_neighbor/lib/python3.12/site-packages/py4j/java_gateway.py\", line 982, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peter/miniconda3/envs/net_neighbor/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1170, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM shutdown complete\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to shutdown JVM\n",
    "bridge.shutdown()\n",
    "print(\"JVM shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net_neighbor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
