{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetNeighbors: Domain Discovery Using CommonCrawl Webgraph\n",
    "\n",
    "**High-Performance JVM Backend**\n",
    "\n",
    "Discover related domains using link topology analysis from the CommonCrawl web graph.\n",
    "\n",
    "This notebook uses py4j to maintain a persistent JVM with the graph loaded in memory.\n",
    "After initial load (~5 seconds), queries are **nearly instant**.\n",
    "\n",
    "**Run the cells below in order to set up and use the discovery tool.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 31.0 GB\n",
      "‚úÖ Sufficient RAM available\n",
      "\n",
      "‚úÖ Changed to NetNeighbors submodule\n",
      "Working directory: /home/peter/dev/apps/NetNeighborsColab/NetNeighbors\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check RAM and setup working directory\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Available RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: You need Colab Pro for this notebook!\")\n",
    "    print(\"   Required: 20GB+ RAM\")\n",
    "    print(f\"   You have: {ram_gb:.1f} GB\")\n",
    "    print(\"\\n   Please enable High-RAM runtime:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Runtime shape: High-RAM\")\n",
    "    raise Exception(\"Insufficient RAM. Please upgrade runtime.\")\n",
    "else:\n",
    "    print(\"‚úÖ Sufficient RAM available\\n\")\n",
    "\n",
    "# Determine NetNeighbors location and set as working directory\n",
    "if os.path.exists(\"/content\"):\n",
    "    # Colab environment\n",
    "    if not os.path.exists(\"/content/NetNeighbors\"):\n",
    "        print(\"Cloning NetNeighbors repository...\")\n",
    "        !git clone --depth 1 https://github.com/PeterCarragher/NetNeighbors.git /content/NetNeighbors > /dev/null 2>&1\n",
    "        print(\"‚úÖ Repository cloned\")\n",
    "    else:\n",
    "        print(\"‚úÖ NetNeighbors repository already exists\")\n",
    "    os.chdir(\"/content/NetNeighbors\")\n",
    "else:\n",
    "    # Local environment\n",
    "    if os.path.exists(\"src/DiscoveryTool.java\"):\n",
    "        print(\"‚úÖ Already in NetNeighbors directory\")\n",
    "    elif os.path.exists(\"NetNeighbors/src/DiscoveryTool.java\"):\n",
    "        os.chdir(\"NetNeighbors\")\n",
    "        print(\"‚úÖ Changed to NetNeighbors submodule\")\n",
    "    else:\n",
    "        raise Exception(\"Cannot find NetNeighbors directory.\")\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Environment Setup\n",
    "\n",
    "Installs Java 17, Maven, py4j, and builds the cc-webgraph tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "           NetNeighbors Environment Setup\n",
      "============================================================\n",
      "Base directory: /home/peter/dev/apps/NetNeighborsColab\n",
      "NetNeighbors: /home/peter/dev/apps/NetNeighborsColab/NetNeighbors\n",
      "Mode: local\n",
      "\n",
      "1. Setting up Java 17 and Maven...\n",
      "   ‚úÖ Java and Maven already installed\n",
      "openjdk version \"17.0.15\" 2025-04-15\n",
      "\n",
      "2. Skipping gcsfuse (local mode, not needed)\n",
      "\n",
      "3. Installing Python dependencies...\n",
      "   ‚úÖ Python dependencies installed\n",
      "\n",
      "4. Setting up cc-webgraph...\n",
      "   ‚úÖ cc-webgraph already built\n",
      "\n",
      "5. Setting up NetNeighbors...\n",
      "   ‚úÖ DiscoveryTool already compiled\n",
      "\n",
      "============================================================\n",
      "                    Setup Complete!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Download webgraph data (use utils.download_webgraph)\n",
      "  2. Run verify.sh to confirm installation\n",
      "\n",
      "‚úÖ py4j installed\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/setup.sh\n",
    "\n",
    "# Install py4j for JVM bridge\n",
    "!pip install -q py4j\n",
    "print(\"\\n‚úÖ py4j installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Configure Storage and Download Webgraph\n",
    "\n",
    "Downloads pre-built graph files from CommonCrawl (~23GB total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local storage: /mnt/d/dev/data/cc/\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_storage, download_webgraph\n",
    "\n",
    "# Webgraph version - see https://commoncrawl.org/web-graphs for available versions\n",
    "VERSION = \"cc-main-2024-feb-apr-may\"\n",
    "\n",
    "# Enter GCS bucket name (or leave empty for local storage)\n",
    "GCS_BUCKET = None #\"commoncrawl_webgraph\" # e.g., \"my-webgraph-bucket\"\n",
    "LOCAL_PATH = \"/mnt/d/dev/data/cc/\"\n",
    "\n",
    "if GCS_BUCKET:\n",
    "  from google.colab import auth; auth.authenticate_user()\n",
    "WEBGRAPH_DIR = setup_storage(bucket_name=GCS_BUCKET, webgraph_dir=LOCAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CommonCrawl webgraph: cc-main-2024-feb-apr-may\n",
      "Destination: /mnt/d/dev/data/cc/\n",
      "============================================================\n",
      "\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-vertices.txt.gz (889.2 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.graph (4298.4 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.properties (0.0 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-t.graph (4275.1 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain-t.properties (0.0 MB)\n",
      "Already exists: cc-main-2024-feb-apr-may-domain.stats (0.0 MB)\n",
      "\n",
      "============================================================\n",
      "All graph files downloaded!\n",
      "\n",
      "Building offset files (required for graph queries)...\n",
      "Offsets already exist: cc-main-2024-feb-apr-may-domain.offsets\n",
      "Offsets already exist: cc-main-2024-feb-apr-may-domain-t.offsets\n",
      "\n",
      "============================================================\n",
      "Webgraph ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Download webgraph files (skip if already downloaded)\n",
    "download_webgraph(WEBGRAPH_DIR, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Graph Bridge (JVM Backend)\n",
    "\n",
    "This starts a persistent JVM and loads the graph into memory.\n",
    "**Takes ~5 seconds**, but then all queries are nearly instant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting JVM with cc-webgraph...\n",
      "JAR: /home/peter/dev/apps/NetNeighborsColab/cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\n",
      "Loading graph: /mnt/d/dev/data/cc/cc-main-2024-feb-apr-may-domain\n",
      "This takes ~5 seconds...\n",
      "‚úÖ Graph loaded!\n",
      "Subsequent queries will be nearly instant!\n",
      "\n",
      "============================================================\n",
      "üöÄ Graph loaded! Queries are now instant.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from graph_bridge import GraphBridge\n",
    "\n",
    "# Initialize and load graph (this is the ~10 second step)\n",
    "bridge = GraphBridge(WEBGRAPH_DIR, VERSION)\n",
    "bridge.load_graph()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Graph loaded! Queries are now instant.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Quick Test\n",
    "\n",
    "Let's verify the bridge is working with a quick query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated 7 domains in 10.0ms\n",
      "Found: ['com.cnn', 'com.bbc', 'com.foxnews', 'com.100percentfedup', 'org.4chan', 'org.911truth']\n",
      "Not found: ['tld.nonexistentdomain']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Test domain lookup (should be instant)\n",
    "test_domains = [\"cnn.com\", \"bbc.com\", \"foxnews.com\", \"100percentfedup.com\", \"nonexistentdomain.tld\", \"4chan.org\", \"911truth.org\"]\n",
    "\n",
    "def reverse_domain(domain: str) -> str:\n",
    "    return '.'.join(reversed(domain.split('.')))\n",
    "\n",
    "reversed_domains = [reverse_domain(d) for d in test_domains]\n",
    "\n",
    "start = time.time()\n",
    "found, not_found = bridge.validate_seeds(reversed_domains)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Validated {len(test_domains)} domains in {elapsed*1000:.1f}ms\")\n",
    "print(f\"Found: {found}\")\n",
    "if not_found:\n",
    "    print(f\"Not found: {not_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovery completed in 0.06 seconds\n",
      "Found 46 domains with >= 6 connections\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['com.50webs',\n",
       " 'com.aifsy',\n",
       " 'com.amgreatness',\n",
       " 'com.angelfire',\n",
       " 'com.bitchute',\n",
       " 'com.blogspot',\n",
       " 'com.dailycaller',\n",
       " 'com.ericpetersautos',\n",
       " 'com.fc2',\n",
       " 'com.forumotion',\n",
       " 'com.globalseoarticles',\n",
       " 'com.henrymakow',\n",
       " 'com.hubpages',\n",
       " 'com.kingranks',\n",
       " 'com.pirdu',\n",
       " 'com.pklea',\n",
       " 'com.ranksdirectory',\n",
       " 'com.salon',\n",
       " 'com.scienceblogs',\n",
       " 'com.shtfplan',\n",
       " 'com.substack',\n",
       " 'com.topbilliondirectory',\n",
       " 'com.typepad',\n",
       " 'com.usawatchdog',\n",
       " 'com.wayranks',\n",
       " 'com.webranksite',\n",
       " 'com.webseodirectory',\n",
       " 'com.weebly',\n",
       " 'com.wnd',\n",
       " 'com.worldranksite',\n",
       " 'net.eturkey',\n",
       " 'net.gatesofvienna',\n",
       " 'net.phibetaiota',\n",
       " 'net.saidit',\n",
       " 'online.99site',\n",
       " 'online.allarticles',\n",
       " 'online.waynews',\n",
       " 'online.wayranks',\n",
       " 'org.freedomclubusa',\n",
       " 'org.horsesass',\n",
       " 'org.rationalwiki',\n",
       " 'org.republicbroadcasting',\n",
       " 'org.softpanorama',\n",
       " 'se.vaken',\n",
       " 'tv.thepeoplesvoice',\n",
       " 'us.thepiratescove']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Direct API usage\n",
    "import time\n",
    "\n",
    "# Run discovery\n",
    "threshold = 6\n",
    "start = time.time()\n",
    "# results = bridge.discover_backlinks(found, min_connections=threshold)\n",
    "results = bridge.shared_predecessors(found)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\nDiscovery completed in {elapsed:.2f} seconds\")\n",
    "print(f\"Found {len(results)} domains with >= {threshold} connections\")\n",
    "# print(\"\\nTop 10 results:\")\n",
    "# for r in results[:10]:\n",
    "#     print(f\"  {r['domain']}: {r['connections']} connections ({r['percentage']}%)\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discovery Interface\n",
    "\n",
    "Use the form below to discover related domains. Queries are **nearly instant** now that the graph is loaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Create input widgets\n",
    "domains_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter seed domains, one per line:\\ncnn.com\\nbbc.com\\nfoxnews.com',\n",
    "    description='',\n",
    "    layout=widgets.Layout(width='80%', height='200px'),\n",
    "    style={'description_width': '0px'}\n",
    ")\n",
    "\n",
    "min_conn_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Min Connections:',\n",
    "    style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='60%')\n",
    ")\n",
    "\n",
    "direction_radio = widgets.RadioButtons(\n",
    "    options=[\n",
    "        ('Backlinks (who links TO seeds)', 'backlinks'),\n",
    "        ('Outlinks (who seeds link TO)', 'outlinks')\n",
    "    ],\n",
    "    value='backlinks',\n",
    "    description='Direction:',\n",
    "    style={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='üöÄ Run Discovery',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px'),\n",
    "    tooltip='Click to discover related domains (instant!)'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Display form\n",
    "display(HTML(\"<h3>Seed Domains</h3>\"))\n",
    "display(HTML(\"<p>Enter one domain per line:</p>\"))\n",
    "display(domains_input)\n",
    "display(HTML(\"<br>\"))\n",
    "display(min_conn_slider)\n",
    "display(HTML(\"<br>\"))\n",
    "display(direction_radio)\n",
    "display(HTML(\"<br>\"))\n",
    "display(run_button)\n",
    "display(HTML(\"<hr>\"))\n",
    "display(output_area)\n",
    "\n",
    "# Button click handler\n",
    "def on_run_click(b):\n",
    "    output_area.clear_output()\n",
    "    \n",
    "    with output_area:\n",
    "        # Validate input\n",
    "        domains_text = domains_input.value.strip()\n",
    "        if not domains_text:\n",
    "            print(\"Error: Please enter at least one domain\")\n",
    "            return\n",
    "        \n",
    "        seed_domains = [d.strip() for d in domains_text.split('\\n') if d.strip()]\n",
    "        \n",
    "        if len(seed_domains) == 0:\n",
    "            print(\"Error: Please enter at least one domain\")\n",
    "            return\n",
    "        \n",
    "        if len(seed_domains) > 10000:\n",
    "            print(\"Error: Maximum 10000 domains allowed\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Seed domains: {len(seed_domains)}\")\n",
    "        print(f\"  Direction: {direction_radio.value}\")\n",
    "        print(f\"  Min connections: {min_conn_slider.value}\")\n",
    "        print()\n",
    "        \n",
    "        try:\n",
    "            # Run discovery (should be fast!)\n",
    "            start_time = time.time()\n",
    "            results = bridge.discover(\n",
    "                seed_domains=seed_domains,\n",
    "                min_connections=min_conn_slider.value,\n",
    "                direction=direction_radio.value\n",
    "            )\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\n‚è±Ô∏è Query completed in {elapsed:.2f} seconds\")\n",
    "            print()\n",
    "            \n",
    "            # Display results\n",
    "            if len(results) == 0:\n",
    "                display(HTML(\"<h3>No Results Found</h3>\"))\n",
    "                print(\"No domains found matching the criteria.\")\n",
    "                print(\"\\nTry:\")\n",
    "                print(\"  - Lowering the minimum connections threshold\")\n",
    "                print(\"  - Using different seed domains\")\n",
    "                print(\"  - Switching between backlinks and outlinks\")\n",
    "            else:\n",
    "                display(HTML(f\"<h3>Found {len(results):,} Domains</h3>\"))\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                results_df = pd.DataFrame(results)\n",
    "                \n",
    "                # Style and display\n",
    "                display(HTML(\"<h4>Top Results:</h4>\"))\n",
    "                \n",
    "                styled_df = results_df.head(100).style.format({\n",
    "                    'connections': '{:,.0f}',\n",
    "                    'percentage': '{:.2f}%'\n",
    "                }).background_gradient(subset=['connections'], cmap='YlOrRd')\n",
    "                \n",
    "                display(styled_df)\n",
    "                \n",
    "                if len(results_df) > 100:\n",
    "                    print(f\"\\n(Showing top 100 of {len(results_df):,} results)\")\n",
    "                \n",
    "                # Summary statistics\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"Summary Statistics:\")\n",
    "                print(f\"  Total discovered: {len(results_df):,} domains\")\n",
    "                print(f\"  Connections range: {results_df['connections'].min():.0f} - {results_df['connections'].max():.0f}\")\n",
    "                print(f\"  Mean connections: {results_df['connections'].mean():.1f}\")\n",
    "                print(f\"  Median connections: {results_df['connections'].median():.0f}\")\n",
    "                print(\"=\"*60)\n",
    "                \n",
    "                # Save to CSV\n",
    "                csv_path = '/content/results.csv' if os.path.exists('/content') else 'results.csv'\n",
    "                results_df.to_csv(csv_path, index=False)\n",
    "                print(f\"\\nüíæ Results saved to {csv_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            display(HTML(\"<h3>Error During Discovery</h3>\"))\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "run_button.on_click(on_run_click)\n",
    "\n",
    "print(\"üí° Tip: Queries are nearly instant now that the graph is loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Programmatic API\n",
    "\n",
    "You can also use the bridge directly for more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get direct predecessors/successors for a single domain\n",
    "domain = \"cnn.com\"\n",
    "\n",
    "start = time.time()\n",
    "backlinks = bridge.get_predecessors(domain)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Found {len(backlinks):,} domains linking to {domain}\")\n",
    "print(f\"Query time: {elapsed*1000:.1f}ms\")\n",
    "print(f\"\\nFirst 10: {backlinks[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "When done, you can shutdown the JVM to free memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:39925)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peter/miniconda3/envs/net_neighbor/lib/python3.12/site-packages/py4j/java_gateway.py\", line 982, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peter/miniconda3/envs/net_neighbor/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1170, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM shutdown complete\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to shutdown JVM\n",
    "bridge.shutdown()\n",
    "print(\"JVM shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net_neighbor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
